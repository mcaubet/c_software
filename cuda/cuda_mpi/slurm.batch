#!/bin/bash -l 
#SBATCH --job-name=testmpi
#SBATCH --error=testmpi.error
#SBATCH --output=testmpi.out
#SBATCH --time=00:02:00
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --ntasks-per-node=2
#SBATCH --cpus-per-task=1
#SBATCH --partition=gpu-test
#SBATCH --account=merlin-gpu
#SBATCH --gres=gpu:GTX1080:2
#SBATCH --exclusive
#SBATCH --nodelist=merlin-g-002

module load gcc/8.4.0 openmpi/4.0.5_slurm

export OMPI_MCA_pml="ucx"
export OMPI_MCA_btl="^vader,tcp,openib,uct"
export UCX_NET_DEVICES=mlx5_0:1
export UCX_LOG_LEVEL=TRACE
export UCX_LOG_FILE=UCX-$SLURM_JOB_ID-$SLURM_NODEID.log
# export UCX_MEMTYPE_CACHE=n

ldd $(which mpirun)

ldd ./cuda_mpi

mpirun ./cuda_mpi
